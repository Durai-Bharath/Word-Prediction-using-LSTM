{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhfyNaCypJbF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = open(\"/content/pg1513.txt\", \"r\", encoding = \"utf8\")\n",
        "file2 = open(\"/content/pg120.txt\", \"r\", encoding = \"utf8\")\n",
        "# file3 = open(\"/content/pg1727.txt\", \"r\", encoding = \"utf8\")\n",
        "# file4 = open(\"/content/1400-0.txt\", \"r\", encoding = \"utf8\")\n",
        "# file5 = open(\"/content/pg1259.txt\", \"r\", encoding = \"utf8\")\n",
        "files= [file1,file2]\n",
        "lines = []\n",
        "for file in files:\n",
        "    for line in file:\n",
        "        lines.append(line)\n",
        "\n",
        "data = \"\"\n",
        "for i in lines:\n",
        "  data = ' '. join(lines)\n",
        "\n",
        "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('“','').replace('”','')  #new line, carriage return, unicode character --> replace by space\n",
        "\n",
        "data = data.split()\n",
        "data = ' '.join(data)\n",
        "data[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "HFFL7CQQpaT_",
        "outputId": "f7932b92-8c79-4806-95f9-a16a2e81e234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Project Gutenberg eBook of Romeo and Juliet, by William Shakespeare This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.org. If you are not located in the United States, you will have to check the laws of the country where you are located before usi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdpsCIhhpqXq",
        "outputId": "f2de8b9a-ad07-4aae-c0d9-e14736b50d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "538169"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "\n",
        "pickle.dump(tokenizer, open('token.pkl', 'wb'))\n",
        "\n",
        "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
        "sequence_data[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yO7xGUKptQk",
        "outputId": "3ef3b891-a190-4484-d501-fac7cd397a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 76, 67, 468, 5, 44, 2, 74, 29, 2508, 2024, 22, 468, 24, 15]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sequence_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRnySzRfpxb5",
        "outputId": "c4cbc45e-d7d6-4654-890e-32a2fc22c1b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "101709"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX08s9gnp51C",
        "outputId": "e5e40162-f798-4e11-8a81-92e5586177a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = []\n",
        "\n",
        "for i in range(2, len(sequence_data)):\n",
        "    words = sequence_data[i-2:i+1]\n",
        "    sequences.append(words)\n",
        "\n",
        "print(\"The Length of sequences are: \", len(sequences))\n",
        "sequences = np.array(sequences)\n",
        "sequences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmqbtKRvqCVS",
        "outputId": "1af65395-c3b3-438e-99d8-0f28be365dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Length of sequences are:  101707\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,   76,   67],\n",
              "       [  76,   67,  468],\n",
              "       [  67,  468,    5],\n",
              "       [ 468,    5,   44],\n",
              "       [   5,   44,    2],\n",
              "       [  44,    2,   74],\n",
              "       [   2,   74,   29],\n",
              "       [  74,   29, 2508],\n",
              "       [  29, 2508, 2024],\n",
              "       [2508, 2024,   22]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in sequences:\n",
        "    X.append(i[0:2])\n",
        "    y.append(i[2])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "BKue7R27qD3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data: \", X[:10])\n",
        "print(\"Response: \", y[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnbPTTpBqFYJ",
        "outputId": "a4adbf16-8851-443b-e339-ef437840dede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data:  [[   1   76]\n",
            " [  76   67]\n",
            " [  67  468]\n",
            " [ 468    5]\n",
            " [   5   44]\n",
            " [  44    2]\n",
            " [   2   74]\n",
            " [  74   29]\n",
            " [  29 2508]\n",
            " [2508 2024]]\n",
            "Response:  [  67  468    5   44    2   74   29 2508 2024   22]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMUEsu11qG9H",
        "outputId": "4e213162-dc4f-495a-b85c-1067064e81ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=2))\n",
        "model.add(LSTM(1000, return_sequences=True))\n",
        "model.add(LSTM(1000))\n",
        "model.add(Dense(1000, activation=\"relu\"))\n",
        "model.add(Dense(vocab_size, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "Mqj_TtW1qIap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BLP_gICqJy9",
        "outputId": "22739263-4669-4c35-8f62-0389c88582c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 2, 10)             86130     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 2, 1000)           4044000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              1001000   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8613)              8621613   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,756,743\n",
            "Trainable params: 21,756,743\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"next_words.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
        "model.fit(X, y, epochs=10, batch_size=64, callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R11ZggZGqLKp",
        "outputId": "4885a680-9205-465f-f973-c62c2248f42b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1590/1590 [==============================] - ETA: 0s - loss: 6.6208\n",
            "Epoch 1: loss improved from inf to 6.62077, saving model to next_words.h5\n",
            "1590/1590 [==============================] - 38s 18ms/step - loss: 6.6208\n",
            "Epoch 2/10\n",
            "1590/1590 [==============================] - ETA: 0s - loss: 6.1045\n",
            "Epoch 2: loss improved from 6.62077 to 6.10448, saving model to next_words.h5\n",
            "1590/1590 [==============================] - 23s 15ms/step - loss: 6.1045\n",
            "Epoch 3/10\n",
            "1588/1590 [============================>.] - ETA: 0s - loss: 5.8016\n",
            "Epoch 3: loss improved from 6.10448 to 5.80169, saving model to next_words.h5\n",
            "1590/1590 [==============================] - 23s 14ms/step - loss: 5.8017\n",
            "Epoch 4/10\n",
            "1590/1590 [==============================] - ETA: 0s - loss: 5.5560\n",
            "Epoch 4: loss improved from 5.80169 to 5.55601, saving model to next_words.h5\n",
            "1590/1590 [==============================] - 23s 15ms/step - loss: 5.5560\n",
            "Epoch 5/10\n",
            "1587/1590 [============================>.] - ETA: 0s - loss: 5.3421\n",
            "Epoch 5: loss improved from 5.55601 to 5.34180, saving model to next_words.h5\n",
            "1590/1590 [==============================] - 23s 14ms/step - loss: 5.3418\n",
            "Epoch 6/10\n",
            "1590/1590 [==============================] - ETA: 0s - loss: 5.1298\n",
            "Epoch 6: loss improved from 5.34180 to 5.12983, saving model to next_words.h5\n",
            "1590/1590 [==============================] - 23s 14ms/step - loss: 5.1298\n",
            "Epoch 7/10\n",
            "1588/1590 [============================>.] - ETA: 0s - loss: 4.9051\n",
            "Epoch 7: loss improved from 5.12983 to 4.90532, saving model to next_words.h5\n",
            "1590/1590 [==============================] - 23s 14ms/step - loss: 4.9053\n",
            "Epoch 8/10\n",
            "1589/1590 [============================>.] - ETA: 0s - loss: 4.6810\n",
            "Epoch 8: loss improved from 4.90532 to 4.68088, saving model to next_words.h5\n",
            "1590/1590 [==============================] - 23s 15ms/step - loss: 4.6809\n",
            "Epoch 9/10\n",
            "1589/1590 [============================>.] - ETA: 0s - loss: 4.4570\n",
            "Epoch 9: loss improved from 4.68088 to 4.45707, saving model to next_words.h5\n",
            "1590/1590 [==============================] - 23s 14ms/step - loss: 4.4571\n",
            "Epoch 10/10\n",
            "1587/1590 [============================>.] - ETA: 0s - loss: 4.2420\n",
            "Epoch 10: loss improved from 4.45707 to 4.24200, saving model to next_words.h5\n",
            "1590/1590 [==============================] - 23s 15ms/step - loss: 4.2420\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f416e0a9190>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = load_model('next_words.h5')\n",
        "tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
        "\n",
        "def Predict_Next_Words(model, tokenizer, text):\n",
        "\n",
        "  sequence = tokenizer.texts_to_sequences([text])\n",
        "  sequence = np.array(sequence)\n",
        "  preds = np.argmax(model.predict(sequence))\n",
        "  predicted_word = \"\"\n",
        "\n",
        "  for key, value in tokenizer.word_index.items():\n",
        "      if value == preds:\n",
        "          predicted_word = key\n",
        "          break\n",
        "\n",
        "  print(predicted_word)\n",
        "  return predicted_word"
      ],
      "metadata": {
        "id": "n35uG9lqqM9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while(True):\n",
        "  text = input(\"Enter your line: \")\n",
        "\n",
        "  if text == \"0\":\n",
        "      print(\"Execution completed.....\")\n",
        "      break\n",
        "\n",
        "  else:\n",
        "      try:\n",
        "          text = text.split(\" \")\n",
        "          text = text[-2:]\n",
        "          print(text)\n",
        "\n",
        "          Predict_Next_Words(model, tokenizer, text)\n",
        "\n",
        "      except Exception as e:\n",
        "        print(\"Error occurred: \",e)\n",
        "        continue\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4qJJdNrqOs8",
        "outputId": "55865080-5b34-4a0b-c681-5b79a1347b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your line: Robert Louis\n",
            "['Robert', 'Louis']\n",
            "1/1 [==============================] - 1s 682ms/step\n",
            "stevenson\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lvg0JzBEqQ4f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}